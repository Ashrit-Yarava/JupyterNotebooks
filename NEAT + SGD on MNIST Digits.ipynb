{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyP6LBdv77n48QPbZsRkqZkP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook tests the ability of the proposed algorithm in finding its efficiency on the MNIST dataset."],"metadata":{"id":"3FbJUBCdwSQI"}},{"cell_type":"code","source":["import torch, torch.nn as nn\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import networkx as nx\n","import numpy as np\n","import pandas as pd\n","import math, random, statistics, itertools\n","from datetime import datetime\n","from sklearn.datasets import fetch_openml\n","from tqdm import tqdm\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"],"metadata":{"id":"IAgrEtlcw4aV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the dataset loader and other utilities for evaluating the model. If the model can learn on this data, push toward other tests."],"metadata":{"id":"MgvmO7h2xBCl"}},{"cell_type":"code","source":["# @title The MNIST Digits Dataset\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))  # MNIST specific normalization\n","])\n","dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n","\n","def sample(sample_size):\n","    return next(iter(DataLoader(dataset, batch_size = sample_size)))"],"metadata":{"id":"tt-r5uEmxJ4c","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title The Innovation Database Class\n","class InnovationDatabase:\n","    def __init__(self):\n","        self.i2n = {}\n","        self.n2i = {}\n","        self.innovation_number = 1\n","\n","    def __setitem__(self, key, value):\n","        if key in self.i2n.keys() or key in self.n2i.keys():\n","            raise Exception(f\"Not Updating Database. Key {key} already exists.\")\n","        if isinstance(key, int):\n","            self.i2n[key] = value\n","            self.n2i[value] = key\n","        else:\n","            self.n2i[key] = value\n","            self.i2n[value] = key\n","\n","    def __getitem__(self, key):\n","        if isinstance(key, int):\n","            return self.i2n[key]\n","        else:\n","            return self.n2i[key]\n","\n","    def __str__(self):\n","        return str(self.i2n)\n","\n","    def innovation(self, edge):\n","        if edge not in self.n2i.keys():\n","            self[edge] = self.innovation_number\n","            self.innovation_number += 1\n","        return self[edge]\n","\n","    def reverse_innovation(self, innovation_number):\n","        if innovation_number not in self.i2n.keys():\n","            return None\n","        return self.i2n[innovation_number]\n","\n","database = InnovationDatabase()"],"metadata":{"cellView":"form","id":"-8iIoLrINOpE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the class that defines each individual in a species. The individual class is centered around a `torch.nn.Module` and also a `nx.DiGraph`. For evaluation, the network uses the DiGraph and during backpropogation, the constructed graph can be used for updating the weights of the model. Modifying the graph allows for mutations in the genome of the individual.\n","\n","The below implementation has the following features:\n","    - Given a graph, the class adapts itself to that network.\n","    - Returning a copy of the graph as a numpy array rather than as a torch array (to make sure the parameters are immutable).\n","    - Evaluation\n","    - Mutations (new edge, new vertex)."],"metadata":{"id":"fgX7LvdexsMQ"}},{"cell_type":"code","source":["# @title The network class\n","class Network(nn.Module):\n","    def __init__(self, inputs, outputs, database, graph=None):\n","        super().__init__()\n","\n","        self.inputs = inputs\n","        self.outputs = outputs\n","        self.database = database\n","        self.params = nn.ParameterDict()\n","        self.flatten = nn.Flatten()\n","\n","        if graph is not None:\n","            self.set_graph(graph)\n","        else:\n","            self.graph = nx.DiGraph()\n","            for i in range(1, inputs + 1):\n","                for o in range(inputs + 1, inputs + outputs + 1):\n","                    self.graph.add_node(i, node=\"input\")\n","                    self.graph.add_node(o, node=\"output\")\n","                    self.graph.add_edge(\n","                        i, o, enabled=True, i_n=self.database.innovation((i, o))\n","                    )\n","                    self.params.update(\n","                        {\n","                            f\"{i}\": nn.Parameter(\n","                                data=nn.Parameter(data=self.new_weight())\n","                            ),\n","                            f\"{o}\": nn.Parameter(\n","                                data=nn.Parameter(data=self.new_weight())\n","                            ),\n","                            f\"{i}_{o}\": nn.Parameter(\n","                                data=nn.Parameter(data=self.new_weight())\n","                            ),\n","                        }\n","                    )\n","\n","    def get_graph(self):\n","        graph = nx.DiGraph()\n","        for node, data in self.graph.nodes(True):\n","            graph.add_node(\n","                node,\n","                weight=np.asarray(self.params.get(f\"{node}\").data),\n","                node=data[\"node\"],\n","            )\n","\n","        for (i, o) in self.graph.edges:\n","            data = self.graph.edges[(i, o)]\n","            graph.add_edge(\n","                i,\n","                o,\n","                weight=np.asarray(self.params.get(f\"{i}_{o}\").data),\n","                enabled=data[\"enabled\"],\n","                i_n=data[\"i_n\"],\n","            )\n","\n","        return graph\n","\n","    def set_graph(self, graph):\n","        self.params.clear()\n","        self.graph = nx.DiGraph()\n","\n","        for node, data in graph.nodes(True):\n","            param = nn.Parameter(data=torch.as_tensor(data[\"weight\"]))\n","            self.params.update({f\"{node}\": param})\n","            self.graph.add_node(node, node=data[\"node\"])\n","\n","        for (i, o) in graph.edges:\n","            data = graph.edges[(i, o)]\n","            param = nn.Parameter(data=torch.as_tensor(data[\"weight\"]))\n","            self.params.update({f\"{i}_{o}\": param})\n","            self.graph.add_edge(i, o, enabled=data[\"enabled\"], i_n=data[\"i_n\"])\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        inputs, outputs = self.get_inputs_and_outputs()\n","        values = {i: x[:, idx] for idx, i in enumerate(inputs)}\n","        eval_stack, evaled_stack = [], []\n","\n","        for i in inputs:\n","            for s in self.graph.successors(i):\n","                if self.graph.edges[(i, s)][\"enabled\"] and s not in eval_stack:\n","                    eval_stack.append(s)\n","\n","        while len(eval_stack) > 0:\n","            node = eval_stack.pop(0)\n","\n","            if node in values.keys():\n","                continue\n","\n","            parents = {\n","                parent\n","                for parent in set(nx.all_neighbors(self.graph, node))\n","                - set(self.graph.successors(node))\n","            }\n","            successors = {\n","                i\n","                for i in set(self.graph.successors(node))\n","                if self.graph.edges[(node, i)][\"enabled\"]\n","            } - set(values.keys())\n","\n","            if len(parents - set(values.keys())) == 0:\n","                value = 0\n","                for parent in parents:\n","                    weight = self.params[f\"{parent}_{node}\"]\n","                    value += weight * values[parent]\n","                value += self.params[f\"{node}\"]\n","                values[node] = torch.relu(value)\n","\n","                eval_stack.extend(successors)\n","            else:\n","                eval_stack.extend(\n","                    parents.union({node}) - set(eval_stack) - set(values.keys())\n","                )\n","\n","        output = torch.stack(\n","            [val for i, val in values.items() if i in outputs],\n","            dim=-1,\n","        )\n","        output = torch.softmax(output, dim=-1)\n","        return output\n","\n","    def mutate_vertex(self):\n","        edge = random.choice(list(self.enabled_edges()))\n","        self.graph.edges[edge][\"enabled\"] = False\n","        i, o = edge\n","        new_node = max(self.graph.nodes) + 1\n","        self.graph.add_node(new_node, node=\"hidden\")\n","        self.graph.add_edge(\n","            i, new_node, enabled=True, i_n=self.database.innovation((i, new_node))\n","        )\n","        self.graph.add_edge(\n","            new_node, i, enabled=True, i_n=self.database.innovation((new_node, i))\n","        )\n","        self.params.update(\n","            {\n","                f\"{new_node}\": nn.Parameter(data=self.new_weight()),\n","                f\"{i}_{new_node}\": nn.Parameter(data=self.new_weight()),\n","                f\"{new_node}_{i}\": nn.Parameter(data=self.new_weight()),\n","            }\n","        )\n","\n","    def mutate_connection(self):\n","        inputs, outputs = self.get_inputs_and_outputs()\n","        nodes = set(self.graph.nodes)\n","\n","        possible = list(\n","            set(\n","                edge\n","                for edge in itertools.product(nodes - outputs, nodes - inputs)\n","                if edge[0] != edge[1]\n","                and edge[1] not in set(nx.ancestors(self.graph, edge[0]))\n","            )\n","            - self.enabled_edges()\n","        )\n","\n","        if len(possible) == 0:\n","            return\n","\n","        random_edge = random.choice(possible)\n","        if random_edge in self.graph.edges:\n","            self.graph.edges[random_edge][\"enabled\"] = True\n","        else:\n","            i, o = random_edge\n","            self.graph.add_edge(\n","                i, o, enabled=True, i_n=self.database.innovation(random_edge)\n","            )\n","            self.params.update({f\"{i}_{o}\": nn.Parameter(data=self.new_weight())})\n","\n","    def plot(self, filename=None, with_weights=False):\n","        node_colors = {\"hidden\": \"blue\", \"input\": \"green\", \"output\": \"red\"}\n","        node_colors = [\n","            node_colors[self.graph.nodes[i][\"node\"]] for i in self.graph.nodes\n","        ]\n","        # Define the edge colors.\n","        edge_colors = [\n","            \"green\" if self.graph.edges[edge][\"enabled\"] else \"red\"\n","            for edge in self.graph.edges\n","        ]\n","        # Define the layout of the drawn genome.\n","        pos = nx.circular_layout(self.graph)\n","\n","        nx.draw(\n","            self.graph,\n","            pos=pos,\n","            with_labels=True,\n","            node_color=node_colors,\n","            edge_color=edge_colors,\n","        )\n","        if with_weights:\n","            edge_labels = {\n","                edge: round(\n","                    float(self.params[f\"{edge[0]}_{edge[1]}\"].data.detach().numpy()), 2\n","                )\n","                for edge in self.graph.edges\n","            }\n","            nx.draw_networkx_edge_labels(\n","                self.graph, pos=pos, edge_labels=edge_labels, font_color=\"green\"\n","            )\n","        if filename is None:\n","            plt.show()\n","            plt.clf()\n","        else:\n","            plt.savefig(filename)\n","            plt.clf()\n","\n","    def clone(self):\n","        return Network(self.inputs, self.outputs, self.database, self.get_graph())\n","\n","    def get_inputs_and_outputs(self):\n","        return {\n","            node for node, data in self.graph.nodes(True) if data[\"node\"] == \"input\"\n","        }, {node for node, data in self.graph.nodes(True) if data[\"node\"] == \"output\"}\n","\n","    def enabled_edges(self):\n","        return {(i, o) for (i, o, enabled) in self.graph.edges.data(\"enabled\")}\n","\n","    def new_weight(self):\n","        return torch.normal(0, 1, size=())"],"metadata":{"id":"HC9rYTycyEFs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perform tests to see if the graphs work."],"metadata":{"id":"qgj77HsplXc1"}},{"cell_type":"code","source":["# Graph Creation\n","net = Network(28 * 28, 10, database)\n","\n","# Graph Mutations\n","for _ in range(10):\n","    net.mutate_connection()\n","    net.mutate_vertex()\n","\n","net.set_graph(net.get_graph())\n","\n","# Graph Evaluation\n","x, y = sample(16)\n","\n","print(f\"Input Shape: {x.shape}\")\n","\n","start_time = datetime.now()\n","print(f\"Output Shape: {net(x).shape}\")\n","end_time = datetime.now()\n","\n","print(f\"Time For Evaluation: {(end_time - start_time).total_seconds()}\")\n","\n","# Plotting\n","# net.plot()"],"metadata":{"id":"rJeBsaqVlZpy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generation\n","\n","As pointed out before, the process in each generation goes as follows, with hyperparameters:\n","\n","$$\n","\\mu = \\text{Population Size}\\\\\n","\\Delta = \\text{Maximum Age of an individual}\\\\\n","\\lambda = \\text{Number of offsprings}\n","$$\n","\n","During each generation, given $\\mu$ individuals, the individuals first generate offspring. The offspring are then mutated. The offspring go through a learning phase where they are trained using SGD for a maximum of $\\Delta$ iterations. Finally, the fitness score is calculated for each individual in the population and the offsprings and the best are kept for the next generation.\n","\n","First things first, test the algorithm without crossover."],"metadata":{"id":"-O9YhAOW6lmp"}},{"cell_type":"code","source":["mu = 5\n","delta = 50\n","lmbda = 5\n","batch_size = 64\n","learning_rate = 1e-4\n","generations = 10"],"metadata":{"id":"mU_Cyq7G9rvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def learn(net):\n","    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n","    losses = []\n","    for iter in range(delta):\n","        optimizer.zero_grad()\n","        x, y = sample(batch_size)\n","        y = y.to(torch.long)\n","\n","        y_hat = net(x)\n","        loss = nn.CrossEntropyLoss()(y_hat, y)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        losses.append(float(loss.item()))\n","\n","    return losses\n","\n","def fitness(net, sample_size):\n","    x, y = sample(sample_size)\n","    y_hat = net(x)\n","    y_hat = torch.argmax(y_hat, axis=-1)\n","    return float(torch.sum(y == y_hat) / sample_size)\n","\n","def fitness_population(population, sample_size):\n","    return np.array([fitness(i, sample_size) for i in population])\n","\n","def generate_offsprings(population, mutate_vertex_prob=0.3):\n","    offsprings = []\n","\n","    for _ in range(lmbda):\n","        random_individual = random.choice(population).clone()\n","\n","        # Only one type of mutation at a time. Could possibly alter this later.\n","        random_individual.mutate_vertex() if random.random() < mutate_vertex_prob else random_individual.mutate_connection()\n","\n","        offsprings.append(random_individual)\n","\n","    return offsprings"],"metadata":{"id":"_yCF2LkG91Q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["population = [Network(28 * 28, 10, database) for _ in range(mu)]\n","losses = [learn(i) for i in tqdm(population)]\n","fitness_scores = fitness_population(population, 64)\n","np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)"],"metadata":{"id":"TxdsFflgEhDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title The process for one iteration.\n","offsprings = generate_offsprings(population)\n","offspring_losses = [learn(individual) for individual in tqdm(offsprings)]\n","\n","combined = population + offsprings\n","combined_fitness = fitness_population(combined, 64)\n","sorted_fitness_indices = np.flip(np.argsort(combined_fitness))\n","\n","new_population = [combined[i] for i in sorted_fitness_indices[:mu]]\n","fitness_scores = np.flip(np.sort(combined_fitness))[:mu]\n","\n","np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)"],"metadata":{"id":"JoF61UfU6oZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Complete Algorithm\n","\n","The algorithm below implements all the ideas with a mutation only generated next generation and SGD for learning during each generation. Since the population trains in the previous generation, it doesn't have to train, therefore, in each generation only train the offsprings since they were mutated. If the mutation works, then the offspring should have the optimal weight values assigned to it."],"metadata":{"id":"n5x34B_kCUnz"}},{"cell_type":"code","source":["# Hyper parameters\n","mu = 1 # Population Size\n","delta = 20 # The Gestation Period (learning phase) of each individual.\n","lmbda = 1 # The number of offsprings generated\n","batch_size = 64 # The batch size used for SGD and fitness score calculation.\n","learning_rate = 1e-4 # The learning rate for SGD.\n","generations = 50 # The number of generations to perform the evolution for.\n","scaling_factor = 10 # The scaling factor for the sine curve.\n","\n","mutate_vertex_probs = np.sin(np.arange(generations) / scaling_factor) + 1\n","\n","# Keep track of some stuff.\n","generational_losses = []\n","generational_fitness = []\n","\n","population = [Network(28 * 28, 10, database) for _ in range(mu)]\n","losses = np.array([learn(i) for i in tqdm(population)]) # The initial population has to learn too.\n","fitness_scores = fitness_population(population, 64)\n","\n","generational_losses.append(np.mean(losses))\n","generational_fitness.append((np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)))\n","\n","print(generational_fitness)"],"metadata":{"id":"IHYwit00DigV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for g in range(generations):\n","\n","    offsprings = generate_offsprings(population, mutate_vertex_prob=mutate_vertex_probs[g])\n","    offspring_losses = [learn(individual) for individual in tqdm(offsprings)]\n","\n","    # Find the mu best amongst the offspring and the population.\n","    combined = population + offsprings\n","    combined_fitness = fitness_population(combined, 64)\n","    sorted_fitness_indices = np.flip(np.argsort(combined_fitness))\n","    new_population = [combined[i] for i in sorted_fitness_indices[:mu]]\n","\n","    fitness_scores = fitness_population(new_population, 64)\n","    generational_losses.append(np.mean(offspring_losses))\n","    generational_fitness.append((np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)))\n","\n","    population = new_population\n","\n","    print(f\"Generation: {g + 1} / {generations}: {generational_fitness[-1]}\\tReplacements: {np.sum(sorted_fitness_indices[:mu] > mu)}, Max Replace: {sorted_fitness_indices[0] == 0}\")"],"metadata":{"id":"p--IAlz5F53e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fitness_scores = pd.DataFrame(generational_fitness, columns=[\"Max\", \"Mean\", \"Min\"])\n","ax = fitness_scores.plot()\n","plt.xlabel(\"Generation #\")\n","plt.ylabel(\"Fitness Score (out of 1)\")\n","plt.title(\"Fitness Scores Over Generations\")\n","\n","best_individual = population[0].get_graph()\n","# population[0].plot()"],"metadata":{"id":"KOLuNGvvG0wS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(population[0].graph.edges))"],"metadata":{"id":"5-idw0I9NzPl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["opt_state = optax.adam(1e-4)(graph)"],"metadata":{"id":"tgJpNeNFrUTu"},"execution_count":null,"outputs":[]}]}