{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyO3Y+KOi7A4TCmZYc5ZbNiT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# NEAT Algorithm Implementation\n","\n","The below notebook implements the originial NEAT algorithm explained in the original paper published by Stanley et. al in 2002. The below implementation takes a functional approach with each genome being functionally represented by a `networkx` graph."],"metadata":{"id":"V2irGnckn6u8"}},{"cell_type":"code","source":["import networkx as nx\n","import numpy as np\n","import pandas as pd\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import matplotlib.image as img\n","\n","import math\n","import statistics\n","import random\n","from typing import List, Tuple, Any, Union, Set\n","import json\n","import itertools\n","from copy import deepcopy\n","import time"],"metadata":{"id":"VlkpxHoAoAQC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Innovation Database\n","\n","The innovation database class handles the innovation number system that was introduced in the NEAT paper. The class holds a dictionary and the inverse dictionary that allows for lookup of the innovation number for the nodes as well as the nodes for the innovation number."],"metadata":{"id":"mvhWUE6Y3VAA"}},{"cell_type":"code","source":["class InnovationDatabase:\n","\n","    def __init__(self):\n","        self.i2n = {}\n","        self.n2i = {}\n","        self.innovation_number = 1\n","\n","    def __setitem__(self, key: Union[Tuple[int, int], int], value: Union[Tuple[int, int], int]):\n","        if key in self.i2n.keys() or key in self.n2i.keys():\n","            raise Exception(f\"Not Updating Database. Key {key} already exists.\")\n","            return\n","        if type(key) is int:\n","            self.i2n[key] = value\n","            self.n2i[value] = key\n","        else:\n","            self.n2i[key] = value\n","            self.i2n[value] = key\n","\n","    def __getitem__(self, key: Union[Tuple[int, int], int]):\n","        if type(key) is int:\n","            return self.i2n[key]\n","        else:\n","            return self.n2i[key]\n","\n","    def __str__(self):\n","        return str(self.i2n)\n","\n","    def innovation(self, edge: Tuple[int, int]) -> int:\n","        if edge not in self.n2i.keys():\n","            self[edge] = self.innovation_number\n","            self.innovation_number += 1\n","        return self[edge]\n","\n","    def reverse_innovation(self, innovation_number: int) -> Union[None, Tuple[int, int]]:\n","        if innovation_number not in self.i2n.keys():\n","            return None\n","        return self.i2n[innovation_number]\n","\n","\n","database = InnovationDatabase()\n","database[(1, 2)] = 3\n","database[4] = (3, 4)\n","print(database[3])\n","print(database[(3, 4)])\n","print(database)"],"metadata":{"id":"FdsB4Pjw3SLZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Iris Flowers Dataset"],"metadata":{"id":"epOSBo1TWWvQ"}},{"cell_type":"code","source":["class IrisFlowers:\n","    def __init__(self, filename):\n","        \"\"\"\n","        Provide a data loader with random sampling and batched\n","        sampling for the Iris Flowers dataset.\n","        \"\"\"\n","        self.file = filename\n","        df = pd.read_csv(self.file)\n","        dataset = df.to_dict(orient=\"list\")\n","        self.variety_to_index = {}\n","        self.index_to_variety = {}\n","\n","        for index, word in enumerate(set(dataset[\"variety\"])):\n","            self.variety_to_index[word] = index\n","            self.index_to_variety[index] = word\n","\n","        df[\"variety\"] = df[\"variety\"].map(self.variety_to_index)\n","        df = df.sample(frac=1)\n","\n","        self.df = df\n","        self.df_np = self.df.to_numpy()\n","        self.length = len(df)\n","\n","    def single_sample(self) -> np.ndarray:\n","        \"\"\"\n","        Return a numpy array with the last row being the labels.\n","        \"\"\"\n","        random_selection = random.randint(0, self.length - 1)\n","        return self.df_np[random_selection]\n","\n","    def batched_sample(self, batch_size: int) -> np.ndarray:\n","        \"\"\"\n","        Return a batched sample as a numpy array.\n","        \"\"\"\n","        random_shuffled_df = np.copy(self.df_np)\n","        np.random.shuffle(random_shuffled_df)\n","        return random_shuffled_df[:batch_size]"],"metadata":{"id":"RpVUxzMzWi0e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Topologically Evolving Artificial Neural Network (TWEANN) Construction\n","\n","Graph sturcture for encoding the TWEANN:\n","\n","- Each node on the graph represents one of the nodes and each edge represents a gene in the genome.\n","- Each node has a `bias` attribute that is added to the function similar to a perceptron where $\\sigma$ is the activation function.\n","$$\n","y= \\sigma(b + \\sum x_i w_i)\n","$$"],"metadata":{"id":"UWOtoP0f5yAP"}},{"cell_type":"code","source":["def print_genome(genome: nx.DiGraph):\n","    dict_genome = nx.to_dict_of_dicts(genome)\n","    print(json.dumps(dict_genome, indent=4))\n","\n","\n","def get_inputs_and_outputs(genome: nx.DiGraph) -> Tuple[Set[int], Set[int]]:\n","    inputs = []\n","    outputs = []\n","    for node in genome.nodes:\n","        if genome.nodes[node][\"node\"] == \"input\":\n","            inputs.append(node)\n","        elif genome.nodes[node][\"node\"] == \"output\":\n","            outputs.append(node)\n","        else:\n","            break\n","    return set(inputs), set(outputs)\n","\n","\n","def plot_genome(genome: nx.DiGraph, with_weights: bool = False) -> None:\n","    # Define the node colors.\n","    node_colors = {\"hidden\": \"blue\", \"input\": \"green\", \"output\": \"red\"}\n","    node_colors = [node_colors[genome.nodes[i][\"node\"]] for i in genome.nodes]\n","    # Define the edge colors.\n","    edge_colors = [\"green\" if genome.edges[edge][\"enabled\"] else \"red\" for edge in genome.edges]\n","    # Define the layout of the drawn genome.\n","    pos = nx.circular_layout(genome)\n","\n","    nx.draw(genome, pos=pos, with_labels=True, node_color=node_colors, edge_color=edge_colors)\n","    if with_weights:\n","        edge_labels = {edge: round(genome.edges[edge][\"w\"], 2) for edge in genome.edges}\n","        nx.draw_networkx_edge_labels(genome, pos=pos, edge_labels=edge_labels, font_color=\"green\")\n","    plt.show()"],"metadata":{"id":"vipOU2zlQ_CC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creation Of Genomes"],"metadata":{"id":"efaniu496J2a"}},{"cell_type":"code","source":["def create_genome(input_len: int, output_len: int, database: InnovationDatabase):\n","    \"\"\"\n","    Create a fully connected network as the base genome with the specified\n","    number of inputs and outputs.\n","    \"\"\"\n","    inputs = list(range(1, input_len + 1))\n","    outputs = list(range(input_len + 1, input_len + output_len + 1))\n","\n","    genome = nx.DiGraph()\n","    genome.add_nodes_from([*[(i, {\"bias\": np.random.normal(), \"node\": \"input\"}) for i in inputs], *[(o, {\"bias\": np.random.normal(), \"node\": \"output\"}) for o in outputs]])\n","    for i in inputs:\n","        for o in outputs:\n","            edge_attr = {\"w\": np.random.normal(), \"enabled\": True, \"i_n\": database.innovation((i, o))}\n","            genome.add_edge(i, o, **edge_attr)\n","\n","    return genome\n","\n","database = InnovationDatabase()\n","genome = create_genome(4, 3, database)"],"metadata":{"id":"OdF1hCXK6NW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Genome Mutations\n","\n","The genome can be mutated in 3 different ways.\n","\n","1. Weight Change: The weight change occurs every iteration with a very high probability and adds a random normal variable scaled to a certain value to the current weight/bias of the genome. The `p = weight_mutation_probability` variable controls whether the weight is mutated if $U(0, 1) < p$, then the weight is mutated.\n","2. Vertex: A random enabled gene is chosen and the gene is disabled and 2 new genes are added with a new node is added between the nodes of the disabled gene and the new node.\n","3. Connection: A new connection is created between 2 nodes that does not already exist. If the connection exists but is disabled, the node is enabled."],"metadata":{"id":"PS9MtiQNUqSm"}},{"cell_type":"code","source":["def mutate_weight(genome: nx.DiGraph, weight_mutation_probability: float, scale: float) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    # Mutate the weights.\n","    for edge in genome.edges:\n","        if np.random.rand() < weight_mutation_probability:\n","            genome.edges[edge][\"w\"] += np.random.normal() * scale\n","    # Mutate the biases\n","    for node in genome.nodes:\n","        if np.random.rand() < weight_mutation_probability:\n","            genome.nodes[node][\"bias\"] += np.random.normal() * scale\n","    return genome\n","\n","def mutate_vertex(genome: nx.DiGraph, database: InnovationDatabase) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    # Pick a random enabled edge:\n","    edge = random.choice([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","    genome.edges[edge][\"enabled\"] = False\n","    in_node, out_node = edge[0], edge[1]\n","    # Get the integer for the new node that can be added.\n","    new_node = max(genome.nodes) + 1\n","    genome.add_node(new_node, bias=np.random.normal(), node=\"hidden\")\n","    genome.add_edges_from([\n","        (in_node, new_node, {\"w\": np.random.normal(),\n","                             \"enabled\": True,\n","                             \"i_n\": database.innovation((in_node, new_node))}\n","         ),\n","        (new_node, out_node, {\"w\": np.random.normal(),\n","                             \"enabled\": True,\n","                             \"i_n\": database.innovation((new_node, out_node))})])\n","    return genome\n","\n","def mutate_connection(genome: nx.DiGraph, database: InnovationDatabase) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    inputs, outputs = get_inputs_and_outputs(genome)\n","    # Get the list of all possible genes that can be made and remove the genes that\n","    # are already in the genome that are enabled.\n","    possible_genes = set(itertools.product(set(genome.nodes) - outputs,\n","                                           set(genome.nodes) - inputs))\n","    possible_genes = {edge for edge in possible_genes if edge[0] != edge[1]}\n","    already_used_genes = set([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","    possible_genes = possible_genes - already_used_genes\n","    possible_genes = [edge for edge in possible_genes if edge[1] not in set(nx.ancestors(genome, edge[0]))]\n","    if len(possible_genes) == 0:\n","        return genome\n","    random_gene = random.choice(possible_genes)\n","    if random_gene in genome.edges:\n","        genome.edges[random_gene][\"enabled\"] = True\n","    else:\n","        genome.add_edge(*random_gene, **{\"w\": np.random.normal(), \"enabled\": True, \"i_n\": database.innovation(random_gene)})\n","    return genome\n","\n","genome = create_genome(4, 3, database)\n","\n","# Test vertex mutations\n","for _ in range(10):\n","    genome = mutate_vertex(genome, database)\n","\n","# Test connection mutations\n","for _ in range(10):\n","    genome = mutate_connection(genome, database)\n","\n","plot_genome(genome)"],"metadata":{"id":"3XjCQ8a9Vdy0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Genome Evaluation\n","\n","The evaluation procedure for a genome, $G$, for a given input $x$ and an evaluation stack.\n","\n","1. Keep track of a value dictionary. The dictionary is updated for each node only once and upon updating the node, the values cannot be changed.\n","2. For each node, if all the parents of the node are in the value dictionary, then calculate the output and set to the value dictionary. If not check if there are any parents that must be added to the evaluation stack and add them. Re-add the node to the stack.\n","3. For each node that has been evaluated, add the successors to the node into the stack if they are not already in the evaluation stack."],"metadata":{"id":"_kqtrwAJ0lYR"}},{"cell_type":"code","source":["def softmax(x):\n","    x -= np.max(x, axis=-1, keepdims=True)\n","    exp_x = np.exp(x)\n","    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n","\n","def evaluate(genome: nx.DiGraph, x: np.ndarray) -> np.ndarray:\n","    inputs, outputs = get_inputs_and_outputs(genome)\n","    values = {i: x[:, idx] for idx, i in enumerate(inputs)}\n","    evaluation_stack = []\n","    evaluated_stack = []\n","    # Add all the successors of the inputs to the evaluation stack.\n","    for i in inputs:\n","        for s in genome.successors(i):\n","            if genome.edges[(i, s)][\"enabled\"] and s not in evaluation_stack:\n","                evaluation_stack.append(s)\n","    # Keep going through the evaluation stack until\n","    while len(evaluation_stack) > 0:\n","        node = evaluation_stack.pop(0)\n","        # Don't evaluate the node if it has already been evaluated.\n","        if node in values.keys():\n","            continue\n","        # Get the enabled parents and successors of the node.\n","        parents = {parent for parent in set(nx.all_neighbors(genome, node)) - set(genome.successors(node)) if genome.edges[(parent, node)][\"enabled\"]}\n","        successors = {i for i in set(genome.successors(node)) if genome.edges[(node, i)][\"enabled\"]} - set(evaluation_stack)\n","        if len(parents - set(values.keys())) == 0:\n","            value = 0\n","            for parent in parents:\n","                value += genome.edges[(parent, node)][\"w\"] * values[parent]\n","            value += genome.nodes[node][\"bias\"]\n","            values[node] = value * (value > 0)\n","            # Add successors that are not in the evaluation stack.\n","            evaluation_stack.extend(successors)\n","        else:\n","            # Add parents that have yet to be evaluated to the evaluation stack.\n","            evaluation_stack.extend(parents.union({node}) - set(evaluation_stack) - set(values.keys()))\n","\n","    output = np.zeros((x.shape[0], len(outputs)))\n","    for idx, i in enumerate(outputs):\n","        output[:, idx] = values[i]\n","    return output\n","\n","x = np.random.rand(16, 4)\n","y_hat = evaluate(genome, x)\n","y_hat.shape"],"metadata":{"id":"UJjKCKeGKZbd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Genome Crossover\n","\n","Genome crossover as defined according to the paper where the matching genes are chosen randomly but the disjoint genes and excess genes are chosen from the more fit parent."],"metadata":{"id":"8wXqRkgwVMxE"}},{"cell_type":"code","source":["ENABLE_CHANCE = 0.2\n","\n","def crossover(genome1: nx.DiGraph, genome2: nx.DiGraph) -> nx.DiGraph:\n","    genome1 = deepcopy(genome1)\n","    innovation_numbers = [edge[2][\"i_n\"] for edge in genome1.edges(data=True)]\n","    # Crossover between the weights.\n","    for edge in genome2.edges:\n","        if edge in genome1.edges:\n","            if np.random.rand() >= 0.5:\n","                continue\n","            genome1.edges[edge][\"w\"] = genome2.edges[edge][\"w\"]\n","            genome1.edges[edge][\"enabled\"] = genome2.edges[edge][\"enabled\"]\n","\n","            if np.random.rand() < ENABLE_CHANCE:\n","                genome1.edges[edge][\"enabled\"] = True\n","\n","    # Crossover between the bias.\n","    for node in genome1.nodes:\n","        if node in genome2.nodes:\n","            genome1.nodes[node][\"bias\"] = genome2.nodes[node][\"bias\"]\n","    return genome1\n","\n","genome1 = create_genome(4, 3, database)\n","# Test vertex mutations\n","for _ in range(10):\n","    genome1 = mutate_vertex(genome, database)\n","# Test connection mutations\n","for _ in range(10):\n","    genome1 = mutate_connection(genome, database)\n","\n","genome2 = create_genome(4, 3, database)\n","# Test vertex mutations\n","for _ in range(10):\n","    genome2 = mutate_vertex(genome, database)\n","# Test connection mutations\n","for _ in range(10):\n","    genome2 = mutate_connection(genome, database)\n","\n","genome = crossover(genome1, genome2)"],"metadata":{"id":"eo0v2yF7eeR9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## NEAT Generation Algorithm\n","\n","The generation process algorithm is for the steps taken in each single individual generation. This takes into account the concept of speciation introduced in the paper to reduce the possibility of dominance of a specific genome architecture. The helper functions are highlighted below:\n","\n","- `score_genome`: Calculate the fitness of an individual genome given a sample $x, y$.\n","- `split_to_species`: Use the compatability threshold and the similarity between the weights and structure of all the genomes. $c_1, c_2, c_3$ are the scaling factors, $D$ is the number of disjoint genes, $E$ is the number of excess genes, $N$ is the total number of genes, and $\\mu_w$ is the average weight difference.\n","$$\n","c_1 \\times \\frac{D}{N} + c_2 \\times \\frac{E}{N} + c_3 \\times \\mu_w\n","$$\n","- `speciated_fitness`: Calculates the fitness of the individuals in the population taking into account the number of species in the population. Given that $f$ is the fitness score of a genome $x$. The more the number of species, the lower the score. The function in the denominator sums the number of individuals in the species.\n","$$\n","f'_i = \\frac{f_i}{\\sum_{j = 1}^n \\text{sh}(\\delta(i, j))}\n","$$"],"metadata":{"id":"vprQxlqUpCYe"}},{"cell_type":"code","source":["N = 100\n","OFFSPRING = int(N * 1.0)\n","ITERATIONS = 1000\n","BATCH_SIZE = 64\n","INPUTS = 4\n","OUTPUTS = 3\n","DELTA_T = 2\n","C1, C2, C3 = 1, 1, 1\n","PR_MUTATE_WEIGHT = 1\n","PR_MUTATE_CONN = 0.5\n","PR_MUTATE_VERTEX = 0.3"],"metadata":{"id":"vFjraBBeL1wL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def score_genome(genome: nx.DiGraph, x: np.ndarray, y: np.ndarray) -> float:\n","    y_hat = evaluate(genome, x)\n","    y_hat = softmax(y_hat)\n","\n","    # Calculate the accuracy\n","    y_ints = np.max(y_hat, axis=-1).astype(np.int32)\n","    accuracy = np.sum(y_ints == y)\n","\n","    return accuracy\n","\n","def score_genome_entropy(genome: nx.DiGraph, x: np.ndarray, y: np.ndarray) -> float:\n","    y = y.astype(np.int32)\n","    y = np.eye(np.max(y) + 1)[y]\n","\n","    y_hat = evaluate(genome, x)\n","    y_hat = np.clip(y_hat, 1e-15, 1 - 1e-15)\n","\n","    cross_entropy = -y * np.log(y_hat) - (1 - y) * np.log(1 - y_hat)\n","    loss = np.mean(np.sum(cross_entropy, axis=-1))\n","\n","    return -loss\n","\n","def calculate_compatability(genome1: nx.DiGraph, genome2: nx.DiGraph) -> Tuple[float, Tuple[float, float, float]]:\n","    in_g1 = set([genome1.edges[edge][\"i_n\"] for edge in genome1.edges])\n","    in_g2 = set([genome2.edges[edge][\"i_n\"] for edge in genome2.edges])\n","\n","    n = max(len(in_g1), len(in_g2))\n","    max_i_n = max(max(in_g1), max(in_g2))\n","\n","    # Average weight difference.\n","    same_in = in_g1.intersection(in_g2)\n","    w_diff = np.array([genome1.edges[edge][\"w\"] - genome2.edges[edge][\"w\"]\n","                       for edge in genome1.edges\n","                       if genome1.edges[edge][\"i_n\"] in same_in])\n","    w_diff = np.mean(np.abs(w_diff))\n","\n","    # Disjoint and Excess Genes\n","    disjoint = {i for i in in_g1.union(in_g2) if i <= max_i_n}\n","    excess = (in_g1.union(in_g2) - in_g1.intersection(in_g2)) - disjoint\n","\n","    p1 = C1 * len(disjoint) / n\n","    p2 = C2 * len(excess) / n\n","    p3 = float(C3 * w_diff)\n","    return p1 + p2 + p3, (p1, p2, p3)\n","\n","def split_to_species(population: List[nx.DiGraph]) -> Tuple[List[List[nx.DiGraph]], List[float]]:\n","    speciated_population = []\n","    deltas = []\n","\n","    for idx, individual in enumerate(population):\n","        if idx == 0:\n","            speciated_population.append([individual])\n","        else:\n","            added = False\n","            for species in speciated_population:\n","                delta, split_values = calculate_compatability(species[0], individual)\n","                if delta < DELTA_T:\n","                    species.append(individual)\n","                    added = True\n","                    break\n","                deltas.append((delta, split_values))\n","            if not added:\n","                speciated_population.append([individual])\n","\n","    return speciated_population, deltas\n","\n","def speciated_fitness(population: List[nx.DiGraph]) -> Tuple[dict[nx.DiGraph, float], dict[nx.DiGraph, float]]:\n","    fitness_dict = {}\n","    sfitness_dict = {}\n","\n","    speciated_population, _ = split_to_species(population)\n","\n","    for species in speciated_population:\n","        num_species = len(species)\n","\n","        for individual in species:\n","            individual_score = score_genome(individual, x, y)\n","            fitness_dict[individual] = individual_score\n","            score_species = individual_score / num_species\n","            sfitness_dict[individual] = score_species\n","\n","    return sfitness_dict, fitness_dict\n","\n","def mutate(genome: nx.DiGraph) -> nx.DiGraph:\n","    genome = mutate_weight(genome, PR_MUTATE_WEIGHT, 1e-3)\n","    if np.random.rand() < PR_MUTATE_VERTEX:\n","        genome = mutate_vertex(genome, database)\n","    if np.random.rand() < PR_MUTATE_CONN:\n","        genome = mutate_connection(genome, database)\n","    return genome\n","\n","\n","database = InnovationDatabase()\n","iris = IrisFlowers(\"data/iris.csv\")\n","\n","# Create the population\n","population = []\n","for _ in range(N):\n","    individual = create_genome(INPUTS, OUTPUTS, database)\n","    population.append(individual)\n","\n","sample = iris.batched_sample(16)\n","x, y = sample[:, :4], sample[:, 4]\n","\n","len(split_to_species(population)[0])\n","\n","score_genome(population[0], x, y)"],"metadata":{"id":"Q6q7Ua14BtD2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["database = InnovationDatabase()\n","iris = IrisFlowers(\"data/iris.csv\")\n","\n","# Create the population\n","population = []\n","for _ in range(N):\n","    individual = create_genome(INPUTS, OUTPUTS, database)\n","    population.append(individual)\n","\n","# -------------\n","# TRAINING STEP\n","# -------------\n","\n","for iter in range(ITERATIONS):\n","    # Sample from the dataset.\n","    sample = iris.batched_sample(BATCH_SIZE)\n","    x, y = sample[:, :4], sample[:, 4]\n","\n","    offsprings = []\n","    random_genome_evaluations = {}\n","    for _ in range(OFFSPRING):\n","        # Select the first genome randomly.\n","        # For efficiency purposes, save the genome score so that the score can be\n","        # recovered later without computation.\n","        random_genome = random.choice(population)\n","        if random_genome not in random_genome_evaluations.keys():\n","            fitness_score = score_genome(random_genome, x, y)\n","            random_genome_evaluations[random_genome] = fitness_score\n","        first_score = random_genome_evaluations[random_genome]\n","\n","        # Calculate the other genome as well, make sure it's not the same genome\n","        # as the first one.\n","        another_random = random.choice(population)\n","        while another_random == random_genome:\n","            another_random = random.choice(population)\n","        if another_random not in random_genome_evaluations.keys():\n","            fitness_score = score_genome(another_random, x, y)\n","            random_genome_evaluations[another_random] = fitness_score\n","        second_score = random_genome_evaluations[another_random]\n","\n","        # Crossover and mutation of each genome.\n","        offspring = crossover(random_genome, another_random) if first_score > second_score else crossover(another_random, random_genome)\n","        offspring = mutate(offspring)\n","\n","        offsprings.append(offspring)\n","\n","    sfitness_offsprings, fitness_offsprings = speciated_fitness(offsprings)\n","    offsprings = sorted(sfitness_offsprings.items(), key=lambda item: item[1], reverse=True)\n","\n","    sfitness_pop, fitness_pop = speciated_fitness(population)\n","    population = sorted(sfitness_pop.items(), key=lambda item: item[1], reverse=True)\n","\n","    pop_idx = off_idx = 0\n","    num_replaced = 0\n","    new_population = []\n","    new_pop_fitness = []\n","\n","\n","    while len(new_population) < N:\n","        pop_fitness = population[pop_idx][1]\n","\n","        if off_idx >= len(offsprings):\n","            new_population.append(population[pop_idx][0])\n","            pop_idx += 1\n","            new_pop_fitness.append(pop_fitness)\n","            continue\n","\n","        off_fitness = offsprings[off_idx][1]\n","\n","        if pop_fitness > off_fitness:\n","            new_population.append(population[pop_idx][0])\n","            pop_idx += 1\n","            new_pop_fitness.append(pop_fitness)\n","        else:\n","            new_population.append(offsprings[off_idx][0])\n","            off_idx += 1\n","            num_replaced += 1\n","            new_pop_fitness.append(off_fitness)\n","\n","    if iter % 10 == 0:\n","        original_pop_fitness = [i[1] for i in population]\n","        print(f\"Iteration: {iter}\")\n","        print(f\"Replaced: {num_replaced}\")\n","        print(f\"Population Fitness: {statistics.mean(original_pop_fitness)}, {max(original_pop_fitness)}\")\n","        print(f\"New Population Fitness: {statistics.mean(new_pop_fitness)}, {max(new_pop_fitness)}\")\n","\n","    population = new_population\n","\n","sample = iris.batched_sample(BATCH_SIZE)\n","x, y = sample[:, :4], sample[:, 4]\n","print(f\"Accuracy: {score_genome_accuracy(genome, x, y)}\")"],"metadata":{"id":"HG7e36VvxtcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in population:\n","    sample = iris.batched_sample(32)\n","    x, y = sample[:, :4], sample[:, 4]\n","    print(f\"Accuracy: {score_genome_accuracy(population[0], x, y)}\")"],"metadata":{"id":"Lt1eTJuDQgkp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qIG5HN2zUa6x"},"execution_count":null,"outputs":[]}]}