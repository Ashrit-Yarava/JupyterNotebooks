{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNdy6MP6NlhcRYaaSK2EfbN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["This notebook aims to combine the concepts of evolutionary programming using the NEAT algorithm with Stochastic Gradient Descent (SGD). One of the issues adding SGD addresses is that the models are now able to learn to get better at the dataset during each 'life' before the fitness score is calculated. This allows for the model to not have to randomly stumble upon the correct weights.\n","\n","This should also remove the need for speciation since speciation's primary goal is to protect mutations. Additionally, the mutation probabilities can be bumped up to maximum since there is no need for weight mutations."],"metadata":{"id":"3FbJUBCdwSQI"}},{"cell_type":"code","source":["import torch, torch.nn as nn\n","import networkx as nx\n","import numpy as np\n","import pandas as pd\n","import math, random, statistics, itertools\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"],"metadata":{"id":"IAgrEtlcw4aV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the dataset loader and other utilities for evaluating the model. If the model can learn on this data, push toward other tests."],"metadata":{"id":"MgvmO7h2xBCl"}},{"cell_type":"code","source":["# @title The Iris Flowers Dataset\n","class IrisFlowers:\n","    def __init__(self, filename):\n","        self.file = filename\n","        df = pd.read_csv(self.file)\n","        dataset = df.to_dict(orient=\"list\")\n","        self.variety_to_index = {}\n","        self.index_to_variety = {}\n","\n","        for index, word in enumerate(set(dataset[\"variety\"])):\n","            self.variety_to_index[word] = index\n","            self.index_to_variety[index] = word\n","\n","        df[\"variety\"] = df[\"variety\"].map(self.variety_to_index)\n","        df = df.sample(frac=1)\n","\n","        self.df = df\n","        self.df_np = self.df.to_numpy()\n","        self.length = len(df)\n","\n","    def single_sample(self) -> np.ndarray:\n","        random_selection = random.randint(0, self.length - 1)\n","        return self.df_np[random_selection]\n","\n","    def batched_sample(self, batch_size: int) -> np.ndarray:\n","        random_shuffled_df = np.copy(self.df_np)\n","        np.random.shuffle(random_shuffled_df)\n","        sample = random_shuffled_df[:batch_size]\n","        return torch.from_numpy(sample[:, :4]), torch.from_numpy(sample[:, 4])\n","\n","dataset = IrisFlowers(\"./iris.csv\")"],"metadata":{"id":"tt-r5uEmxJ4c","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title The Innovation Database Class.\n","class InnovationDatabase:\n","\n","    def __init__(self):\n","        self.i2n = {}\n","        self.n2i = {}\n","        self.innovation_number = 1\n","\n","    def __setitem__(self, key, value):\n","        if key in self.i2n.keys() or key in self.n2i.keys():\n","            raise Exception(f\"Not Updating Database. Key {key} already exists.\")\n","            return\n","        if type(key) is int:\n","            self.i2n[key] = value\n","            self.n2i[value] = key\n","        else:\n","            self.n2i[key] = value\n","            self.i2n[value] = key\n","\n","    def __getitem__(self, key):\n","        if type(key) is int:\n","            return self.i2n[key]\n","        else:\n","            return self.n2i[key]\n","\n","    def __str__(self):\n","        return str(self.i2n)\n","\n","    def innovation(self, edge):\n","        if edge not in self.n2i.keys():\n","            self[edge] = self.innovation_number\n","            self.innovation_number += 1\n","        return self[edge]\n","\n","    def reverse_innovation(self, innovation_number):\n","        if innovation_number not in self.i2n.keys():\n","            return None\n","        return self.i2n[innovation_number]\n","\n","database = InnovationDatabase()"],"metadata":{"cellView":"form","id":"-8iIoLrINOpE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create the class that defines each individual in a species. The individual class is centered around a `torch.nn.Module` and also a `nx.DiGraph`. For evaluation, the network uses the DiGraph and during backpropogation, the constructed graph can be used for updating the weights of the model. Modifying the graph allows for mutations in the genome of the individual.\n","\n","The below implementation has the following features:\n","    - Given a graph, the class adapts itself to that network.\n","    - Returning a copy of the graph as a numpy array rather than as a torch array (to make sure the parameters are immutable).\n","    - Evaluation\n","    - Mutations (new edge, new vertex)."],"metadata":{"id":"fgX7LvdexsMQ"}},{"cell_type":"code","source":["# @title The Individual Class that controls all the evaluation, learning, and mutations.\n","class Network(nn.Module):\n","    def __init__(self, inputs: int, outputs: int, graph: nx.DiGraph = None):\n","        super().__init__()\n","\n","        self.graph = nx.DiGraph()\n","        self.inputs_and_outputs = (inputs, outputs)\n","        self.params = nn.ParameterDict()\n","\n","        if graph is None:\n","\n","            self.graph.add_nodes_from([\n","                *[(i, {\"node\": \"input\"}) for i in range(1, inputs + 1)],  # The inputs\n","                *[(o, {\"node\": \"output\"}) for o in range(inputs + 1, inputs + outputs + 1)]  # The outputs\n","            ])\n","            self.params = nn.ParameterDict({\n","                **{f\"{i}\": nn.Parameter(data=torch.normal(0, 1, size=())) for i in range(1, inputs + 1)},\n","                **{f\"{i}\": nn.Parameter(data=torch.normal(0, 1, size=())) for i in range(inputs + 1, inputs + outputs + 1)},\n","            })\n","\n","            self.params.update((str(i), nn.Parameter( data=torch.normal(0, 1, size=()) )) for i in range(1, inputs + 1))\n","            self.params.update((str(i), nn.Parameter( data=torch.normal(0, 1, size=()) )) for i in range(inputs + 1, inputs + outputs + 1))\n","\n","            for i in range(1, inputs + 1):\n","                for o in range(inputs + 1, inputs + outputs + 1):\n","                    self.params.update({f\"{i}_{o}\": nn.Parameter(data=torch.normal(0, 1, size=())) })\n","                    edge_attr = {\"enabled\": True, \"i_n\": database.innovation((i, o))}\n","                    self.graph.add_edge(i, o, **edge_attr)\n","        else:\n","            self.set_graph(graph)\n","\n","    def get_graph(self):\n","        graph = nx.DiGraph()\n","\n","        for node in self.graph.nodes:\n","            graph.add_node(node, weight=np.asarray(self.params.get( str(node) ).data), node=self.graph.nodes[node][\"node\"])\n","\n","        for (i, o) in self.graph.edges:\n","            graph.add_edge(i, o, weight=np.asarray(self.params.get( f\"{i}_{o}\" ).data), enabled=self.graph.edges[(i, o)][\"enabled\"], i_n=self.graph.edges[(i, o)][\"i_n\"])\n","\n","        return graph\n","\n","    def set_graph(self, graph):\n","        self.params.clear()\n","        self.graph = nx.DiGraph()\n","\n","        for node in graph.nodes:\n","            parameter = nn.Parameter( data=torch.as_tensor(graph.nodes[node][\"weight\"]) )\n","            self.params.update(((str(node), parameter),))\n","            self.graph.add_node(node, node=graph.nodes[node][\"node\"])\n","\n","        for (i, o) in graph.edges:\n","            data = torch.as_tensor(graph.edges[(i, o)][\"weight\"])\n","            self.params.update(\n","                ((f\"{i}_{o}\", nn.Parameter(data=data)),)\n","            )\n","            self.graph.add_edge(i, o, enabled=graph.edges[(i, o)][\"enabled\"], i_n=graph.edges[(i, o)][\"i_n\"])\n","\n","    @staticmethod\n","    def get_inputs_and_outputs(graph):\n","        inputs = []\n","        outputs = []\n","        for node in graph.nodes:\n","            if graph.nodes[node][\"node\"] == \"input\":\n","                inputs.append(node)\n","            elif graph.nodes[node][\"node\"] == \"output\":\n","                outputs.append(node)\n","            else:\n","                break\n","        return set(inputs), set(outputs)\n","\n","    def forward(self, x):\n","        inputs, outputs = Network.get_inputs_and_outputs(self.graph)\n","        values = {i: x[:, idx] for idx, i in enumerate(inputs)}\n","        eval_stack, evaluated_stack = [], []\n","\n","        # Add all the successors of the inputs to the evaluation stack.\n","        for i in inputs:\n","            for s in self.graph.successors(i):\n","                if self.graph.edges[(i, s)][\"enabled\"] and s not in eval_stack:\n","                    eval_stack.append(s)\n","\n","        # Keep going through the eval_stack until it's empty.\n","        while len(eval_stack) > 0:\n","            node = eval_stack.pop(0)\n","\n","            # Don't evaluate the node if it has already been evaluated.\n","            if node in values.keys():\n","                continue\n","\n","            # Get the enabled parents and the successors of the node.\n","            parents = {parent for parent in set(nx.all_neighbors(self.graph, node)) - set(self.graph.successors(node)) if self.graph.edges[(parent, node)][\"enabled\"]}\n","            successors = {i for i in set(self.graph.successors(node)) if self.graph.edges[(node, i)][\"enabled\"]} - set(eval_stack)\n","\n","            if len(parents - set(values.keys())) == 0:\n","                value = 0\n","                for parent in parents:\n","                    weight = self.params[f\"{parent}_{node}\"]\n","                    value += weight * values[parent]\n","                value += self.params[f\"{node}\"]\n","                values[node] = torch.relu(value)\n","                # Add successors that are not in the evaluation stack.\n","                eval_stack.extend(successors)\n","            else:\n","                eval_stack.extend(parents.union({node}) - set(eval_stack) - set(values.keys()))\n","\n","        output = torch.zeros((x.shape[0], len(outputs)))\n","        for idx, i in enumerate(outputs):\n","            output[:, idx] = values[i]\n","        output = torch.softmax(output, dim=-1)\n","        return output\n","\n","    def mutate_vertex(self):\n","        self.zero_grad()\n","        genome = self.get_graph()\n","        edge = random.choice([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","        genome.edges[edge][\"enabled\"] = False\n","        in_node, out_node = edge[0], edge[1]\n","        # Get the integer for the new node that can be added.\n","        new_node = max(genome.nodes) + 1\n","        genome.add_node(new_node, weight=torch.normal(0, 1, size=()), node=\"hidden\")\n","        genome.add_edges_from([\n","            (in_node, new_node, {\"weight\": np.random.normal(),\n","                                \"enabled\": True,\n","                                \"i_n\": database.innovation((in_node, new_node))}\n","            ),\n","            (new_node, out_node, {\"weight\": np.random.normal(),\n","                                \"enabled\": True,\n","                                \"i_n\": database.innovation((new_node, out_node))})])\n","        self.set_graph(genome)\n","\n","    def mutate_connection(self):\n","        genome = self.get_graph()\n","        inputs, outputs = Network.get_inputs_and_outputs(genome)\n","        # Get the list of all possible genes that can be made and remove the genes that\n","        # are already in the genome that are enabled.\n","        possible_genes = set(itertools.product(set(genome.nodes) - outputs,\n","                                            set(genome.nodes) - inputs))\n","        possible_genes = {edge for edge in possible_genes if edge[0] != edge[1]}\n","        already_used_genes = set([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","        possible_genes = possible_genes - already_used_genes\n","        possible_genes = [edge for edge in possible_genes if edge[1] not in set(nx.ancestors(genome, edge[0]))]\n","        if len(possible_genes) == 0:\n","            return genome\n","        random_gene = random.choice(possible_genes)\n","        if random_gene in genome.edges:\n","            genome.edges[random_gene][\"enabled\"] = True\n","        else:\n","            genome.add_edge(*random_gene, **{\"weight\": torch.normal(0, 1, size=()), \"enabled\": True, \"i_n\": database.innovation(random_gene)})\n","        self.set_graph(genome)\n","\n","    def plot(self, with_weights=False):\n","        node_colors = {\"hidden\": \"blue\", \"input\": \"green\", \"output\": \"red\"}\n","        node_colors = [node_colors[self.graph.nodes[i][\"node\"]] for i in self.graph.nodes]\n","        # Define the edge colors.\n","        edge_colors = [\"green\" if self.graph.edges[edge][\"enabled\"] else \"red\" for edge in self.graph.edges]\n","        # Define the layout of the drawn genome.\n","        pos = nx.circular_layout(self.graph)\n","\n","        nx.draw(self.graph, pos=pos, with_labels=True, node_color=node_colors, edge_color=edge_colors)\n","        if with_weights:\n","            edge_labels = {edge: round(float(self.params[f\"{edge[0]}_{edge[1]}\"].data.detach().numpy()), 2) for edge in self.graph.edges}\n","            nx.draw_networkx_edge_labels(self.graph, pos=pos, edge_labels=edge_labels, font_color=\"green\")\n","        plt.show()\n","\n","    def clone(self):\n","        inputs, outputs = self.inputs_and_outputs\n","        return Network(inputs, outputs, self.get_graph())"],"metadata":{"id":"HC9rYTycyEFs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perform tests to see if the graphs work."],"metadata":{"id":"qgj77HsplXc1"}},{"cell_type":"code","source":["# Graph Creation\n","net = Network(4, 3)\n","\n","# Graph Mutations\n","for _ in range(10):\n","    net.mutate_connection()\n","    net.mutate_vertex()\n","\n","# Graph Evaluation\n","x, y = dataset.batched_sample(16)\n","print(f\"Input Shape: {x.shape}\")\n","print(f\"Output Shape: {net(x).shape}\")\n","\n","# Plotting\n","net.plot()"],"metadata":{"id":"rJeBsaqVlZpy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generation\n","\n","As pointed out before, the process in each generation goes as follows, with hyperparameters:\n","\n","$$\n","\\mu = \\text{Population Size}\\\\\n","\\Delta = \\text{Maximum Age of an individual}\\\\\n","\\lambda = \\text{Number of offsprings}\n","$$\n","\n","During each generation, given $\\mu$ individuals, the individuals first generate offspring. The offspring are then mutated. The offspring go through a learning phase where they are trained using SGD for a maximum of $\\Delta$ iterations. Finally, the fitness score is calculated for each individual in the population and the offsprings and the best are kept for the next generation.\n","\n","First things first, test the algorithm without crossover."],"metadata":{"id":"-O9YhAOW6lmp"}},{"cell_type":"code","source":["mu = 10\n","delta = 200\n","lmbda = 10\n","batch_size = 32\n","learning_rate = 1e-4\n","generations = 10"],"metadata":{"id":"mU_Cyq7G9rvw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def learn(net):\n","    optimizer = torch.optim.Adam(params=net.parameters(), lr=learning_rate)\n","    losses = []\n","    for iter in range(delta):\n","        optimizer.zero_grad()\n","        x, y = dataset.batched_sample(batch_size)\n","        y = y.to(torch.long)\n","\n","        y_hat = net(x)\n","        loss = nn.CrossEntropyLoss()(y_hat, y)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        losses.append(float(loss.item()))\n","\n","    return losses\n","\n","def fitness(net, sample_size):\n","    x, y = dataset.batched_sample(sample_size)\n","    y_hat = net(x)\n","    y_hat = torch.argmax(y_hat, axis=-1)\n","\n","    return float(torch.sum(y == y_hat) / sample_size)\n","\n","def fitness_population(population):\n","    return np.array([fitness(i) for i in population])\n","\n","def generate_offsprings(population, mutate_vertex_prob=0.3):\n","    offsprings = []\n","\n","    for _ in range(lmbda):\n","        random_individual = random.choice(population).clone()\n","\n","        # Only one type of mutation at a time. Could possibly alter this later.\n","        random_individual.mutate_vertex() if random.random() < mutate_vertex_prob else random_individual.mutate_connection()\n","\n","        offsprings.append(random_individual)\n","\n","    return offsprings"],"metadata":{"id":"_yCF2LkG91Q2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["population = [Network(4, 3) for _ in range(mu)]\n","losses = [learn(i) for i in population]\n","fitness_scores = fitness_population(population)\n","np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)"],"metadata":{"id":"TxdsFflgEhDT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# @title The process for one iteration.\n","offsprings = generate_offsprings(population)\n","offspring_losses = [learn(individual) for individual in offsprings]\n","\n","combined = population + offsprings\n","combined_fitness = [fitness(individual) for individual in combined]\n","sorted_fitness_indices = np.flip(np.argsort(combined_fitness))\n","\n","new_population = [combined[i] for i in sorted_fitness_indices[:mu]]\n","\n","fitness_scores = fitness_population(new_population)\n","np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)"],"metadata":{"id":"JoF61UfU6oZT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Complete Algorithm\n","\n","The algorithm below implements all the ideas with a mutation only generated next generation and SGD for learning during each generation. Since the population trains in the previous generation, it doesn't have to train, therefore, in each generation only train the offsprings since they were mutated. If the mutation works, then the offspring should have the optimal weight values assigned to it."],"metadata":{"id":"n5x34B_kCUnz"}},{"cell_type":"code","source":["# Hyper parameters\n","mu = 15 # Population Size\n","delta = 300 # The Gestation Period (learning phase) of each individual.\n","lmbda = 10 # The number of offsprings generated\n","batch_size = 64 # The batch size used for SGD and fitness score calculation.\n","learning_rate = 1e-4 # The learning rate for SGD.\n","generations = 30 # The number of generations to perform the evolution for.\n","scaling_factor = 10 # The scaling factor for the sine curve.\n","\n","mutate_vertex_probs = np.sin(np.arange(generations) / scaling_factor) + 1\n","\n","# Keep track of some stuff.\n","generational_losses = []\n","generational_fitness = []\n","\n","population = [Network(4, 3) for _ in range(mu)]\n","losses = np.array([learn(i) for i in population]) # The initial population has to learn too.\n","fitness_scores = fitness_population(population)\n","\n","generational_losses.append(np.mean(losses))\n","generational_fitness.append((np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)))\n","\n","print(generational_fitness)"],"metadata":{"id":"IHYwit00DigV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for g in range(generations):\n","\n","    offsprings = generate_offsprings(population, mutate_vertex_prob=mutate_vertex_probs[g])\n","    offspring_losses = [learn(individual) for individual in offsprings]\n","\n","    # Find the mu best amongst the offspring and the population.\n","    combined = population + offsprings\n","    combined_fitness = [fitness(individual) for individual in combined]\n","    sorted_fitness_indices = np.flip(np.argsort(combined_fitness))\n","    new_population = [combined[i] for i in sorted_fitness_indices[:mu]]\n","\n","    fitness_scores = fitness_population(new_population)\n","    generational_losses.append(np.mean(offspring_losses))\n","    generational_fitness.append((np.max(fitness_scores), np.mean(fitness_scores), np.min(fitness_scores)))\n","\n","    population = new_population\n","\n","    print(f\"Generation: {g + 1} / {generations}: {generational_fitness[-1]}\\tReplacements: {np.sum(sorted_fitness_indices[:mu] > mu)}, Max Replace: {sorted_fitness_indices[0] == 0}\")"],"metadata":{"id":"p--IAlz5F53e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","fitness_scores = pd.DataFrame(generational_fitness, columns=[\"Max\", \"Mean\", \"Min\"])\n","ax = fitness_scores.plot()\n","plt.xlabel(\"Generation #\")\n","plt.ylabel(\"Fitness Score (out of 1)\")\n","plt.title(\"Fitness Scores Over Generations\")\n","\n","best_individual = population[0].get_graph()\n","# population[0].plot()"],"metadata":{"id":"KOLuNGvvG0wS"},"execution_count":null,"outputs":[]}]}