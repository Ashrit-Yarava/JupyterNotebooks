{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"private_outputs":true,"authorship_tag":"ABX9TyM+1LDqgTMx+wx4JPnE2AD0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["While torch seems easier to use, JAX also optimizes python code, so it might be faster than using torch? This notebook attempts to check that. NOTE: this notebook only has the SGD part of the algorithm.\n","\n","In theory, this should be just fine. Since JAX recompiles for static argnames, passing it as a static variable should have no issues with the graph. Again using params as a seperate variable so that the network graph doesn't interact with the graph should be helpful.\n","\n","The exact implementation, however, is the purpose of this notebook."],"metadata":{"id":"PdhsWRATJygG"}},{"cell_type":"code","source":["import jax\n","import jax.numpy as jnp\n","import jax.random as jr\n","import numpy as np\n","import haiku as hk\n","import optax\n","import networkx as nx\n","import random\n","import pandas as pd\n","from datetime import datetime\n","from tqdm import tqdm\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","sns.set()"],"metadata":{"id":"vzaSB_FBKBhV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Functional Approach\n","\n","Maybe using graphs and pytrees is the way to go? Use the methods from before to manage the graphs and for evaluation, convert the weights to pytree weights and keep the graph as a static argument. The weights can be optimized for the pytree.\n","\n","The graph construction and mutation functions are as follows:\n","\n","1. `create_graph(num_inputs: int, num_outputs: int) -> nx.DiGraph`\n","2. `vertex(graph: nx.DiGraph) -> nx.DiGraph`\n","3. `connection(graph: nx.Digraph) -> nx.DiGraph`\n","\n","A utility plot function is also below which plots the DAG."],"metadata":{"id":"TvXDEVP32E_O"}},{"cell_type":"code","source":["def create_graph(num_inputs, num_outputs):\n","    graph = nx.DiGraph()\n","    for i in range(1, num_inputs + 1):\n","        for o in range(num_inputs + 1, num_inputs + num_outputs + 1):\n","            graph.add_node(i, node=\"input\", weight=np.random.normal())\n","            if i == 1:\n","                graph.add_node(o, node=\"output\", weight=np.random.normal())\n","            graph.add_edge(i, o, enabled=True, weight=np.random.normal())\n","    return graph\n","\n","def vertex(graph):\n","    graph = nx.DiGraph(graph)\n","    i, o = random.choice(list(graph.edges))\n","    graph.edges[(i, o)][\"enabled\"] = False\n","    new_node = max(graph.nodes) + 1\n","    graph.add_node(new_node, node=\"hidden\", weight=np.random.normal())\n","    graph.add_edge(i, new_node, enabled=True, weight=np.random.normal())\n","    graph.add_edge(new_node, o, enabled=True, weight=np.random.normal())\n","    return graph\n","\n","def connection(graph):\n","    graph = nx.DiGraph(graph)\n","    nodes = set(graph.nodes)\n","    inputs = {node for node in graph.nodes if graph.nodes[node][\"node\"] == \"input\"}\n","    outputs = {node for node in graph.nodes if graph.nodes[node][\"node\"] == \"output\"}\n","\n","    not_choosable = []\n","    while True:\n","        in_nodes = list(nodes - outputs - set(not_choosable))\n","        if len(in_nodes) == 0:\n","            return graph\n","        in_node = random.choice(in_nodes)\n","        out_nodes = nodes - inputs - {in_node} - set(nx.ancestors(graph, in_node))\n","        if len(out_nodes) == 0:\n","            not_choosable.append(in_node)\n","            continue\n","        out_node = random.choice(list(out_nodes))\n","        break\n","    if (in_node, out_node) in graph.edges:\n","        graph.edges[(in_node, out_node)][\"enabled\"] = True\n","    else:\n","        graph.add_edge(in_node, out_node, enabled=True, weight=np.random.normal())\n","    return graph\n","\n","def random_graph(inputs, outputs, mutations):\n","    graph = create_graph(inputs, outputs)\n","    for _ in range(mutations):\n","        graph = connection(vertex(graph))\n","    return graph\n","\n","graph = random_graph(4, 3, 5)"],"metadata":{"id":"ctxx8O-A2HGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_graph(graph, ax):\n","    if not nx.is_directed_acyclic_graph(graph):\n","        return\n","    topological_order = list(nx.topological_sort(graph))\n","    pos = {}\n","    y = 0\n","    for generation in nx.topological_generations(graph):\n","        for x, node in enumerate(generation):\n","            if graph.nodes[node][\"node\"] == \"output\":\n","                continue\n","            pos[node] = (x, y)\n","        y += 1\n","    for x, node in enumerate([n for n in graph.nodes if graph.nodes[n][\"node\"] == \"output\"]):\n","        pos[node] = (x, y)\n","    nx.draw(graph, pos=pos, with_labels=True, ax=ax)"],"metadata":{"id":"333QwOw3Q98l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation and SGD\n","\n","This part of the notebook focuses on the evaluation and SGD algorithm used to train each graph. The graph first needs to be broken down into a pytree of the weights and the graph itself.\n","\n","Params have to be converted to an immutable dict since a regular dictionary isn't hashable. Similar to how a regular list isn't hashable."],"metadata":{"id":"xFAgzQ8UURFm"}},{"cell_type":"code","source":["def get_params(graph):\n","    params = {\n","        **{f\"{node}\": jnp.array(graph.nodes[node][\"weight\"], dtype=jnp.float32) for node in graph.nodes},\n","        **{f\"{i}_{o}\": jnp.array(graph.edges[(i, o)][\"weight\"], dtype=jnp.float32) for i, o in graph.edges}\n","    }\n","    return hk.data_structures.to_immutable_dict(params)\n","\n","def set_params(graph, params):\n","    graph = nx.DiGraph(graph)\n","    for node in graph.nodes:\n","        graph.nodes[node][\"weight\"] = params[f\"{node}\"]\n","    for i, o in graph.edges:\n","        graph.edges[(i, o)][\"weight\"] = params[f\"{i}_{o}\"]\n","    return graph\n","\n","params = get_params(graph)"],"metadata":{"id":"jJcOC5noUfFi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate(graph, params, x):\n","    inputs = [node for node in graph.nodes if graph.nodes[node][\"node\"] == \"input\"]\n","    outputs = [node for node in graph.nodes if graph.nodes[node][\"node\"] == \"output\"]\n","    values = {i: x[:, idx] for idx, i in enumerate(inputs)}\n","    eval_stack, evaled_stack = [], []\n","\n","    for i in inputs:\n","        for s in graph.successors(i):\n","            if graph.edges[(i, s)][\"enabled\"] and s not in eval_stack:\n","                eval_stack.append(s)\n","\n","    while len(eval_stack) > 0:\n","        node = eval_stack.pop(0)\n","\n","        # Don't evaluate the node if it has already been evaluated.\n","        if node in values.keys():\n","            continue\n","\n","        # Get the enabled parents and the successors of the node.\n","        parents = {parent for parent in set(nx.all_neighbors(graph, node)) - set(graph.successors(node)) if graph.edges[(parent, node)][\"enabled\"]}\n","        successors = set(graph.successors(node)) - set(eval_stack)\n","\n","        if len(parents - set(values.keys())) == 0:\n","            value = 0\n","            for parent in parents:\n","                weight = params[f\"{parent}_{node}\"]\n","                value += weight * values[parent]\n","            value += params[f\"{node}\"]\n","            values[node] = jax.nn.relu(value)\n","            # Add successors that are not in the evaluation stack.\n","            eval_stack.extend(successors)\n","        else:\n","            eval_stack.extend(parents.union({node}) - set(eval_stack) - set(values.keys()))\n","\n","    output = jnp.stack([val for i, val in values.items() if i in outputs], axis=-1)\n","    output = jax.nn.softmax(output, axis=-1)\n","    return output\n","\n","evaluate_jit = jax.jit(evaluate, static_argnums=(0,))\n","x = np.random.normal(size=(16, 4))\n","evaluate(graph, params, x).shape"],"metadata":{"id":"tmBhKygtbXi-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test stuff about the efficiency of using `JIT` in this context."],"metadata":{"id":"OPQ2z2bk2Aj8"}},{"cell_type":"code","source":["graph = random_graph(4, 3, 200)\n","params = get_params(graph)\n","\n","n = 10\n","regular_evaluate_times = []\n","jit_evaluate_times = []\n","\n","for _ in range(10):\n","    x = jnp.asarray(np.random.normal(size=(16, 4)))\n","    start = datetime.now()\n","    y = evaluate(graph, params, x)\n","    end = datetime.now()\n","\n","    regular_evaluate_times.append((end - start).total_seconds())\n","\n","    start = datetime.now()\n","    y = evaluate_jit(graph, params, x).block_until_ready()\n","    end = datetime.now()\n","\n","    jit_evaluate_times.append((end - start).total_seconds())\n","\n","plt.plot(regular_evaluate_times)\n","plt.plot(jit_evaluate_times)"],"metadata":{"id":"hnrRL49c3PGI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check the values are consistent between a JITted function and the non JITed version."],"metadata":{"id":"dFrHqJQN99uS"}},{"cell_type":"markdown","source":["# Only SGD Optimization\n","\n","Test the optimization capabilities of the evaluate function. It should be fairly straightforward."],"metadata":{"id":"7fesmDUe-U_m"}},{"cell_type":"code","source":["# @title The Iris Flowers Dataset\n","class IrisFlowers:\n","    def __init__(self, filename):\n","        self.file = filename\n","        df = pd.read_csv(self.file)\n","        dataset = df.to_dict(orient=\"list\")\n","        self.variety_to_index = {}\n","        self.index_to_variety = {}\n","\n","        for index, word in enumerate(set(dataset[\"variety\"])):\n","            self.variety_to_index[word] = index\n","            self.index_to_variety[index] = word\n","\n","        df[\"variety\"] = df[\"variety\"].map(self.variety_to_index)\n","        df = df.sample(frac=1)\n","\n","        self.df = df\n","        self.df_np = self.df.to_numpy()\n","        self.length = len(df)\n","\n","    def single_sample(self) -> np.ndarray:\n","        random_selection = random.randint(0, self.length - 1)\n","        return self.df_np[random_selection]\n","\n","    def batched_sample(self, batch_size: int) -> np.ndarray:\n","        random_shuffled_df = np.copy(self.df_np)\n","        np.random.shuffle(random_shuffled_df)\n","        sample = random_shuffled_df[:batch_size]\n","        x, y = jnp.asarray(sample[:, :4]), jnp.asarray(sample[:, 4])\n","        y = y.astype(jnp.int32)\n","        return x, y\n","\n","dataset = IrisFlowers(\"./iris.csv\")"],"metadata":{"cellView":"form","id":"1tD3q_xMCKFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cross_entropy(y_hat, y, labels):\n","    y = jax.nn.one_hot(y, labels)\n","    entropy = -y * jnp.log(y_hat) - (1 - y) * jnp.log(1 - y_hat)\n","    loss = np.mean(np.sum(entropy, axis=-1))\n","    return loss\n","\n","def loss_fn(params, graph, x, y):\n","    y_hat = evaluate(graph, params, x)\n","    return cross_entropy(y_hat, y, 3)\n","\n","\n","loss_fn = jax.value_and_grad(loss_fn)\n","\n","x, y = dataset.batched_sample(16)\n","loss, grads = loss_fn(params, graph, x, y)\n","\n","print(loss)"],"metadata":{"id":"Cw96_w7V_FaX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy_fn(graph, params, x, y):\n","    y_hat = evaluate(graph, params, x)\n","    y_hat = jnp.argmax(y_hat, axis=-1)\n","    return jnp.sum((y == y_hat) / y.shape[0])\n","\n","def step(graph, params, opt_state, x, y):\n","    loss, grads = loss_fn(params, graph, x, y)\n","    updates, opt_state = optimizer.update(grads, opt_state)\n","    params = optax.apply_updates(params, updates)\n","\n","    return loss, params, opt_state\n","\n","step_jit = jax.jit(step, static_argnums=(0,))\n","accuracy_fn_jit = jax.jit(accuracy_fn, static_argnums=(0,))\n","\n","graph = random_graph(4, 3, 10)\n","params = get_params(graph)\n","optimizer = optax.adam(1e-4)\n","opt_state = optimizer.init(params)\n","x, y = dataset.batched_sample(16)\n","\n","loss, params, opt_state = step(graph, params, opt_state, x, y)\n","graph = set_params(graph, params)"],"metadata":{"id":"40TZC_Ewg8V2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test everything out in a loop."],"metadata":{"id":"DPNS16A8jWkF"}},{"cell_type":"code","source":["graph = random_graph(4, 3, 30)\n","params = get_params(graph)\n","optimizer = optax.adam(1e-4)\n","opt_state = optimizer.init(params)\n","\n","losses = []\n","accuracies = []\n","runtimes = []\n","\n","for _ in tqdm(range(5000)):\n","    x, y = dataset.batched_sample(64)\n","    s = datetime.now()\n","    loss, params, opt_state = step_jit(graph, params, opt_state, x, y)\n","    e = datetime.now()\n","\n","    x, y = dataset.batched_sample(128)\n","    accuracy = accuracy_fn_jit(graph, params, x, y)\n","\n","    losses.append(loss)\n","    accuracies.append(accuracy)\n","    runtimes.append((e - s).total_seconds())\n","\n","fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1)\n","ax1.plot(losses[::10])\n","ax1.set_title(\"Loss Plot\")\n","ax2.plot(accuracies[::10])\n","ax2.set_title(\"Accuracy Plot\")\n","plt.tight_layout()"],"metadata":{"id":"HvTawULsjfRH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses"],"metadata":{"id":"_wIyI62HHXUk"},"execution_count":null,"outputs":[]}]}