{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPdhDKfxaCyHkogK+Vv0mk+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Graph Based Neural Networks\n","\n","While neural networks are currently implemented in popular deep learning libraries using matrix manipulation. They are limiting in terms of requiring matrix mulitplication. This notebook attempts to create a neural network structure that deals with perceptrons and individually calculating the weights of the algorithm. Using the torch backpropogation, it should be easy to calculate the gradients for updating a model.\n","\n","The code replicates the code used for the functional NEAT algorithm."],"metadata":{"id":"B1vTJpNS9nKW"}},{"cell_type":"code","source":["import networkx as nx\n","import torch, torch.nn as nn\n","import numpy as np\n","import os, sys, random, statistics\n","import pandas as pd\n","from copy import deepcopy\n","\n","from typing import Tuple, List, Any, Set, Union\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","print(f\"Torch Version: {torch.__version__}\")\n","print(f\"NetworkX Version: {nx.__version__}\")"],"metadata":{"id":"9RUVe5yiDinG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Innovation Database"],"metadata":{"id":"zJm2OqvJ1fyN"}},{"cell_type":"code","source":["class InnovationDatabase:\n","\n","    def __init__(self):\n","        self.i2n = {}\n","        self.n2i = {}\n","        self.innovation_number = 1\n","\n","    def __setitem__(self, key: Union[Tuple[int, int], int], value: Union[Tuple[int, int], int]):\n","        if key in self.i2n.keys() or key in self.n2i.keys():\n","            raise Exception(f\"Not Updating Database. Key {key} already exists.\")\n","            return\n","        if type(key) is int:\n","            self.i2n[key] = value\n","            self.n2i[value] = key\n","        else:\n","            self.n2i[key] = value\n","            self.i2n[value] = key\n","\n","    def __getitem__(self, key: Union[Tuple[int, int], int]):\n","        if type(key) is int:\n","            return self.i2n[key]\n","        else:\n","            return self.n2i[key]\n","\n","    def __str__(self):\n","        return str(self.i2n)\n","\n","    def innovation(self, edge: Tuple[int, int]) -> int:\n","        if edge not in self.n2i.keys():\n","            self[edge] = self.innovation_number\n","            self.innovation_number += 1\n","        return self[edge]\n","\n","    def reverse_innovation(self, innovation_number: int) -> Union[None, Tuple[int, int]]:\n","        if innovation_number not in self.i2n.keys():\n","            return None\n","        return self.i2n[innovation_number]\n","\n","\n","database = InnovationDatabase()"],"metadata":{"id":"zt-hEEB61hym"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Iris Flowers Dataset"],"metadata":{"id":"QxoG3KNuQJn_"}},{"cell_type":"code","source":["class IrisFlowers:\n","    def __init__(self, filename):\n","        \"\"\"\n","        Provide a data loader with random sampling and batched\n","        sampling for the Iris Flowers dataset.\n","        \"\"\"\n","        self.file = filename\n","        df = pd.read_csv(self.file)\n","        dataset = df.to_dict(orient=\"list\")\n","        self.variety_to_index = {}\n","        self.index_to_variety = {}\n","\n","        for index, word in enumerate(set(dataset[\"variety\"])):\n","            self.variety_to_index[word] = index\n","            self.index_to_variety[index] = word\n","\n","        df[\"variety\"] = df[\"variety\"].map(self.variety_to_index)\n","        df = df.sample(frac=1)\n","\n","        self.df = df\n","        self.df_np = self.df.to_numpy()\n","        self.length = len(df)\n","\n","    def single_sample(self) -> np.ndarray:\n","        \"\"\"\n","        Return a numpy array with the last row being the labels.\n","        \"\"\"\n","        random_selection = random.randint(0, self.length - 1)\n","        return self.df_np[random_selection]\n","\n","    def batched_sample(self, batch_size: int) -> np.ndarray:\n","        \"\"\"\n","        Return a batched sample as a numpy array.\n","        \"\"\"\n","        random_shuffled_df = np.copy(self.df_np)\n","        np.random.shuffle(random_shuffled_df)\n","        return torch.from_numpy(random_shuffled_df[:batch_size])\n","\n","iris = IrisFlowers(\"data/iris.csv\")"],"metadata":{"id":"NRgAlxS4QMfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Neural Network Implementation"],"metadata":{"id":"dk-s7hmW3GZb"}},{"cell_type":"code","source":["def get_inputs_and_outputs(genome: nx.DiGraph) -> Tuple[Set[int], Set[int]]:\n","    inputs = []\n","    outputs = []\n","    for node in genome.nodes:\n","        if genome.nodes[node][\"node\"] == \"input\":\n","            inputs.append(node)\n","        elif genome.nodes[node][\"node\"] == \"output\":\n","            outputs.append(node)\n","        else:\n","            break\n","    return set(inputs), set(outputs)\n","\n","\n","class Network(nn.Module):\n","\n","    def __init__(self, inputs: int, outputs: int, graph: nx.DiGraph = None) -> None:\n","        super().__init__()\n","\n","        if graph is None:\n","\n","            self.params = nn.ParameterDict({\n","                **{f\"{i}\": nn.Parameter(data=torch.normal(0, 1, size=())) for i in range(1, inputs + 1)},\n","                **{f\"{i}\": nn.Parameter(data=torch.normal(0, 1, size=())) for i in range(inputs + 1, inputs + outputs + 1)},\n","            })\n","\n","            self.graph = nx.DiGraph()\n","            self.graph.add_nodes_from([\n","                *[(i, {\"bias\": self.params[str(i)].data, \"node\": \"input\"}) for i in range(1, inputs + 1)],  # The inputs\n","                *[(o, {\"bias\": self.params[str(o)].data, \"node\": \"output\"}) for o in range(inputs + 1, inputs + outputs + 1)]  # The outputs\n","            ])\n","\n","            for i in range(1, inputs + 1):\n","                for o in range(inputs + 1, inputs + outputs + 1):\n","                    self.params[f\"{i}_{o}\"] = nn.Parameter(data=torch.normal(0, 1, size=()))\n","                    edge_attr = {\"w\": self.params[f\"{i}_{o}\"].data, \"enabled\": True, \"i_n\": database.innovation((i, o))}\n","                    self.graph.add_edge(i, o, **edge_attr)\n","        else:\n","            # A graph has been given, update the network to follow the graph.\n","            self.params = nn.ParameterDict(**{\n","                f\"{node}\": nn.Paramter(data=graph.nodes[node][\"bias\"]) for node in graph.nodes\n","            }, **{\n","                f\"{edge[0]}_{edge[1]}\": nn.Parameter(data=graph.edges[edge][\"w\"]) for edge in graph.edges\n","            })\n","            self.graph = graph\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","\n","        inputs, outputs = get_inputs_and_outputs(self.graph)\n","        values = {i: x[:, idx] for idx, i in enumerate(inputs)}\n","        eval_stack, evaluated_stack = [], []\n","\n","        # Add all the successors of the inputs to the evaluation stack.\n","        for i in inputs:\n","            for s in self.graph.successors(i):\n","                if self.graph.edges[(i, s)][\"enabled\"] and s not in eval_stack:\n","                    eval_stack.append(s)\n","\n","        # Keep going through the eval_stack until it's empty.\n","        while len(eval_stack) > 0:\n","            node = eval_stack.pop(0)\n","\n","            # Don't evaluate the node if it has already been evaluated.\n","            if node in values.keys():\n","                continue\n","\n","            # Get the enabled parents and the successors of the node.\n","            parents = {parent for parent in set(nx.all_neighbors(self.graph, node)) - set(self.graph.successors(node)) if self.graph.edges[(parent, node)][\"enabled\"]}\n","            successors = {i for i in set(self.graph.successors(node)) if self.graph.edges[(node, i)][\"enabled\"]} - set(eval_stack)\n","\n","            if len(parents - set(values.keys())) == 0:\n","                value = 0\n","                for parent in parents:\n","                    weight = self.params[f\"{parent}_{node}\"]\n","                    value += weight * values[parent]\n","                value += self.params[f\"{node}\"]\n","                values[node] = torch.relu(value)\n","                # Add successors that are not in the evaluation stack.\n","                eval_stack.extend(successors)\n","            else:\n","                eval_stack.extend(parents.union({node}) - set(eval_stack) - set(values.keys()))\n","\n","        output = torch.zeros((x.shape[0], len(outputs)))\n","        for idx, i in enumerate(outputs):\n","            output[:, idx] = values[i]\n","        output = torch.softmax(output, dim=-1)\n","        return output\n","\n","    def get_graph(self) -> nx.DiGraph:\n","        \"\"\"\n","        Returns a copy of the graph.\n","        \"\"\"\n","        return deepcopy(self.graph)\n","\n","\n","\n","database = InnovationDatabase()\n","net = Network(4, 3)\n","a = net.params[\"1\"]\n","\n","x = torch.rand((16, 4))\n","\n","y = net.forward(x)\n","y.shape"],"metadata":{"id":"iqVqQpFxEY-U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Gradient Descent on Genome\n","\n","The addition of the torch module and autograd should allow for the genome to learn in addition to evolving."],"metadata":{"id":"17mh5v3f7OU3"}},{"cell_type":"code","source":["ITERATIONS = 5000\n","# net = Network(4, 3)\n","net = torch.nn.Sequential(nn.Linear(4, 3), nn.Softmax(-1))\n","optimizer = torch.optim.Adam(params=net.parameters(), lr=1e-4)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","for iter in range(ITERATIONS):\n","    optimizer.zero_grad()\n","\n","    sample = torch.from_numpy(iris.batched_sample(16))\n","    x, y = sample[:, :4], sample[:, 4]\n","    x = x.to(torch.float)\n","    y = y.to(torch.long)\n","\n","    y_hat = net(x)\n","    loss = loss_fn(y_hat, y)\n","\n","    loss.backward()\n","    optimizer.step()\n","\n","    if iter % 20 == 0:\n","        print(f\"Iteration: {iter}\\tLoss: {loss.item()}\")"],"metadata":{"id":"qQGOdwjz9cp1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Mutations\n","\n","Test whether the training algorithm works with mutations of connections and vertices. With successful training of mutations, the model should be capable of learning and going through a 'life.'"],"metadata":{"id":"78YcyL4dme_y"}},{"cell_type":"code","source":["def mutate_weight(genome: nx.DiGraph, weight_mutation_probability: float, scale: float) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    # Mutate the weights.\n","    for edge in genome.edges:\n","        if np.random.rand() < weight_mutation_probability:\n","            genome.edges[edge][\"w\"] += torch.normal(0, 1, size=()) * scale\n","    # Mutate the biases\n","    for node in genome.nodes:\n","        if np.random.rand() < weight_mutation_probability:\n","            genome.nodes[node][\"bias\"] += torch.normal(0, 1, size=()) * scale\n","    return genome\n","\n","def mutate_vertex(genome: nx.DiGraph, database: InnovationDatabase) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    # Pick a random enabled edge:\n","    edge = random.choice([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","    genome.edges[edge][\"enabled\"] = False\n","    in_node, out_node = edge[0], edge[1]\n","    # Get the integer for the new node that can be added.\n","    new_node = max(genome.nodes) + 1\n","    genome.add_node(new_node, bias=torch.normal(0, 1, size=()), node=\"hidden\")\n","    genome.add_edges_from([\n","        (in_node, new_node, {\"w\": torch.normal(0, 1, size=()),\n","                             \"enabled\": True,\n","                             \"i_n\": database.innovation((in_node, new_node))}\n","         ),\n","        (new_node, out_node, {\"w\": torch.normal(0, 1, size=()),\n","                             \"enabled\": True,\n","                             \"i_n\": database.innovation((new_node, out_node))})])\n","    return genome\n","\n","def mutate_connection(genome: nx.DiGraph, database: InnovationDatabase) -> nx.DiGraph:\n","    genome = deepcopy(genome)\n","    inputs, outputs = get_inputs_and_outputs(genome)\n","    # Get the list of all possible genes that can be made and remove the genes that\n","    # are already in the genome that are enabled.\n","    possible_genes = set(itertools.product(set(genome.nodes) - outputs,\n","                                           set(genome.nodes) - inputs))\n","    possible_genes = {edge for edge in possible_genes if edge[0] != edge[1]}\n","    already_used_genes = set([edge for edge in genome.edges if genome.edges[edge][\"enabled\"]])\n","    possible_genes = possible_genes - already_used_genes\n","    possible_genes = [edge for edge in possible_genes if edge[1] not in set(nx.ancestors(genome, edge[0]))]\n","    if len(possible_genes) == 0:\n","        return genome\n","    random_gene = random.choice(possible_genes)\n","    if random_gene in genome.edges:\n","        genome.edges[random_gene][\"enabled\"] = True\n","    else:\n","        genome.add_edge(*random_gene, **{\"w\": torch.normal(0, 1, size=()), \"enabled\": True, \"i_n\": database.innovation(random_gene)})\n","    return genome\n","\n","genome = Net(4, 3)"],"metadata":{"id":"HokrOoF6neZ4"},"execution_count":null,"outputs":[]}]}